{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Quick Start",
   "id": "c6735e99f338ace8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!pip install openai==1.57.0\n",
    "!pip install langchain==0.3.10\n",
    "!pip install langchain-community==0.3.10\n",
    "!pip install langchain-core==0.3.22\n",
    "!pip install langchain-openai==0.2.11"
   ],
   "id": "686cfcbb0f14da20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 典型用法",
   "id": "125313536ecd556f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T03:45:11.220880Z",
     "start_time": "2024-12-08T03:45:06.746603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"对技术术语做名词解释：{name}?\")\n",
    "chat = ChatOpenAI(model_name=\"openai/gpt-4o-mini\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | chat | parser\n",
    "\n",
    "res = chain.invoke({\"name\": \"微服务架构\"})\n",
    "print(res)"
   ],
   "id": "cd70b47ba9ddd115",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "微服务架构是一种软件架构风格，它将应用程序拆分成一系列小的、独立的服务，每个服务都围绕特定的业务功能构建。这些服务可以独立部署、扩展和更新，并通过轻量级的通信协议（如HTTP/REST、消息队列等）进行交互。\n",
      "\n",
      "微服务架构的主要特点包括：\n",
      "\n",
      "1. **模块化**：每个微服务都专注于某一特定的功能，具有清晰的边界和职责，便于理解和维护。\n",
      "\n",
      "2. **独立性**：各个微服务可以独立开发、测试和部署，不会影响到其他服务。\n",
      "\n",
      "3. **技术多样性**：不同的微服务可以使用不同的编程语言、框架和技术栈，从而选择最适合特定需求的工具。\n",
      "\n",
      "4. **弹性和可扩展性**：微服务可以根据负载进行水平扩展，能够更好地应对流量变化。\n",
      "\n",
      "5. **持续交付**：微服务架构支持持续集成和持续交付（CI/CD），使得新功能和修复能够快速发布。\n",
      "\n",
      "6. **故障隔离**：由于服务之间的独立性，某个服务的故障不会直接影响到整个应用，这提高了系统的稳定性和可靠性。\n",
      "\n",
      "微服务架构常用于构建复杂的分布式系统，尤其适合需要快速迭代和频繁发布的场景。\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 基本使用",
   "id": "68ca702f93d6df79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T15:28:43.716420Z",
     "start_time": "2024-12-07T15:28:41.176169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 将 OpenAI API 的调用经验迁移过来\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model_name = \"openai/gpt-4o-mini\"\n",
    "llm = ChatOpenAI(model_name=model_name, temperature=0.8)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are an excellent translator, you are very at translating between English and Chinese\"),\n",
    "    # HumanMessage(content=\"Welcome to LLM development with langchain\"),\n",
    "    HumanMessage(content=\"欢迎使用 Langchain 进行大模型开发\")\n",
    "]\n",
    "\n",
    "# 常规输出\n",
    "res = llm.invoke(messages)\n",
    "\n",
    "print(res.content)"
   ],
   "id": "f58febb030b5abec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to using Langchain for large model development!\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T15:36:34.046775Z",
     "start_time": "2024-12-07T15:36:31.712850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 流式输出\n",
    "res = llm.stream(messages)\n",
    "\n",
    "for chunk in res:\n",
    "    print(chunk.content, end=\"|\")\n"
   ],
   "id": "ca87ceb44d11811",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Welcome| to| using| Lang|chain| for| large| model| development|!|||"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T03:15:06.128500Z",
     "start_time": "2024-12-08T03:15:01.437064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# PromptTemplate\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一个优秀的翻译专家，非常擅长把中文翻译为{language}\"),\n",
    "        (\"user\", \"{text}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = prompt_template.invoke({\"language\": \"英文\", \"text\": \"欢迎使用 Langchain 进行大模型开发\"})\n",
    "\n",
    "print(prompt, \"\\n\")\n",
    "\n",
    "# prompt.to_messages() 返回符合上一节预期的 message\n",
    "print(prompt.to_messages(), \"\\n\")\n",
    "\n",
    "model_name = \"openai/gpt-4o-mini\"\n",
    "chat = ChatOpenAI(model_name=model_name)\n",
    "\n",
    "# 用于上一节相同的方式进行问答\n",
    "res = chat.invoke(prompt.to_messages())\n",
    "print(res.content, \"\\n\")\n",
    "\n",
    "# 简化写法\n",
    "res = chat.invoke(prompt)\n",
    "print(res.content, \"\\n\")\n"
   ],
   "id": "78f7af2efc0f2a7c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='你是一个优秀的翻译专家，非常擅长把中文翻译为英文', additional_kwargs={}, response_metadata={}), HumanMessage(content='欢迎使用 Langchain 进行大模型开发', additional_kwargs={}, response_metadata={})] \n",
      "\n",
      "[SystemMessage(content='你是一个优秀的翻译专家，非常擅长把中文翻译为英文', additional_kwargs={}, response_metadata={}), HumanMessage(content='欢迎使用 Langchain 进行大模型开发', additional_kwargs={}, response_metadata={})] \n",
      "\n",
      "Welcome to using Langchain for large model development! \n",
      "\n",
      "Welcome to using Langchain for large model development! \n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Structured Output",
   "id": "87c902a320071113"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Using Json Mode",
   "id": "68b7f8ff52513879"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T11:36:28.537731Z",
     "start_time": "2024-12-08T11:36:25.624262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model_name = \"openai/gpt-4o-mini\"\n",
    "chat = ChatOpenAI(\n",
    "    model_name=model_name,\n",
    "    model_kwargs={\n",
    "        \"response_format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": {\n",
    "                \"name\": \"email_schema\",\n",
    "                \"schema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"email\": {\n",
    "                            \"description\": \"The email address that appears in the input\",\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"additionalProperties\": False\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "resp = chat.invoke([\n",
    "    SystemMessage(content=\"You extract email addresses into JSON data.\"),\n",
    "    HumanMessage(content=\"Feeling stuck? Send a message to help@mycompany.com.\")\n",
    "])\n",
    "\n",
    "print(resp.content)"
   ],
   "id": "4daff72268b519e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"email\":\"help@mycompany.com\"}\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T11:38:15.106928Z",
     "start_time": "2024-12-08T11:38:12.651338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"openai/gpt-4o-mini\")\n",
    "chat.bind(response_format={\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": {\n",
    "                \"name\": \"email_schema\",\n",
    "                \"schema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"email\": {\n",
    "                            \"description\": \"The email address that appears in the input\",\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"additionalProperties\": False\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "\n",
    "resp = chat.invoke([\n",
    "    SystemMessage(content=\"You extract email addresses into JSON data.\"),\n",
    "    HumanMessage(content=\"Feeling stuck? Send a message to help@mycompany.com.\")\n",
    "])\n",
    "\n",
    "print(resp.content)"
   ],
   "id": "731c397cebf1a4de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"email\": \"help@mycompany.com\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T11:38:04.060158Z",
     "start_time": "2024-12-08T11:38:00.602345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"openai/gpt-4o-mini\")\n",
    "chat.bind(response_format={\"type\": \"json_object\"})\n",
    "\n",
    "resp = chat.invoke([\n",
    "    SystemMessage(content=\"You extract email addresses into JSON data.\"),\n",
    "    HumanMessage(content=\"Feeling stuck? Send a message to help@mycompany.com.\")\n",
    "])\n",
    "\n",
    "print(resp.content)"
   ],
   "id": "94d3ec3a73ab8f06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"email\": \"help@mycompany.com\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T11:38:25.666947Z",
     "start_time": "2024-12-08T11:38:23.452199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"openai/gpt-4o-mini\",\n",
    "                  model_kwargs={\n",
    "                      \"response_format\": {\"type\": \"json_object\"}\n",
    "                  })\n",
    "chat.bind(response_format={\"type\": \"json_object\"})\n",
    "\n",
    "resp = chat.invoke([\n",
    "    SystemMessage(content=\"You extract email addresses into JSON data.\"),\n",
    "    HumanMessage(content=\"Feeling stuck? Send a message to help@mycompany.com.\")\n",
    "])\n",
    "\n",
    "print(resp.content)"
   ],
   "id": "fbc5d79a4ac6e7d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"email_addresses\": [\n",
      "    \"help@mycompany.com\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Using Structured Output",
   "id": "3743f75a716a57f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9a3f3a75f3fa5fec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Using Tool calling",
   "id": "a09e95a489e19196"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "38faebf9235b74d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ModelIO\n",
    "\n",
    "- Format: PromptTemplate\n",
    "- Predict: ChatModel/LLM\n",
    "- Parse: OutputParser"
   ],
   "id": "46c78917f3223e51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "## Quick Start",
   "id": "fddbe24e2d8b0600"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## PromptTemplate",
   "id": "6c143496c16cc268"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3b6a36e4fa10ffc3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ChatModel",
   "id": "b06139ca93ad1fa4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9014d4dfc27b4aae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## OutputParser",
   "id": "a9fcf4254f1d12b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6f5d952544e1beb9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
