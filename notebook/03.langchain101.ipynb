{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Quick Start",
   "id": "c6735e99f338ace8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!pip install openai==1.57.0\n",
    "!pip install langchain==0.3.10\n",
    "!pip install langchain-community==0.3.10\n",
    "!pip install langchain-core==0.3.22\n",
    "!pip install langchain-openai==0.2.11"
   ],
   "id": "686cfcbb0f14da20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T15:28:43.716420Z",
     "start_time": "2024-12-07T15:28:41.176169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model_name = \"openai/gpt-4o-mini\"\n",
    "llm = ChatOpenAI(model_name=model_name, temperature=0.8)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are an excellent translator, you are very at translating between English and Chinese\"),\n",
    "    # HumanMessage(content=\"Welcome to LLM development with langchain\"),\n",
    "    HumanMessage(content=\"欢迎使用 Langchain 进行大模型开发\")\n",
    "]\n",
    "\n",
    "# 常规输出\n",
    "res = llm.invoke(messages)\n",
    "\n",
    "print(res.content)"
   ],
   "id": "f58febb030b5abec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to using Langchain for large model development!\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T15:36:34.046775Z",
     "start_time": "2024-12-07T15:36:31.712850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 流式输出\n",
    "res = llm.stream(messages)\n",
    "\n",
    "for chunk in res:\n",
    "    print(chunk.content, end=\"|\")\n"
   ],
   "id": "ca87ceb44d11811",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Welcome| to| using| Lang|chain| for| large| model| development|!|||"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T03:15:06.128500Z",
     "start_time": "2024-12-08T03:15:01.437064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# PromptTemplate\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一个优秀的翻译专家，非常擅长把中文翻译为{language}\"),\n",
    "        (\"user\", \"{text}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = prompt_template.invoke({\"language\": \"英文\", \"text\": \"欢迎使用 Langchain 进行大模型开发\"})\n",
    "\n",
    "print(prompt, \"\\n\")\n",
    "\n",
    "# prompt.to_messages() 返回符合上一节预期的 message\n",
    "print(prompt.to_messages(), \"\\n\")\n",
    "\n",
    "model_name = \"openai/gpt-4o-mini\"\n",
    "chat = ChatOpenAI(model_name=model_name)\n",
    "\n",
    "# 用于上一节相同的方式进行问答\n",
    "res = chat.invoke(prompt.to_messages())\n",
    "print(res.content, \"\\n\")\n",
    "\n",
    "# 简化写法\n",
    "res = chat.invoke(prompt)\n",
    "print(res.content, \"\\n\")\n"
   ],
   "id": "78f7af2efc0f2a7c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='你是一个优秀的翻译专家，非常擅长把中文翻译为英文', additional_kwargs={}, response_metadata={}), HumanMessage(content='欢迎使用 Langchain 进行大模型开发', additional_kwargs={}, response_metadata={})] \n",
      "\n",
      "[SystemMessage(content='你是一个优秀的翻译专家，非常擅长把中文翻译为英文', additional_kwargs={}, response_metadata={}), HumanMessage(content='欢迎使用 Langchain 进行大模型开发', additional_kwargs={}, response_metadata={})] \n",
      "\n",
      "Welcome to using Langchain for large model development! \n",
      "\n",
      "Welcome to using Langchain for large model development! \n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ModelIO\n",
    "\n",
    "- Format: PromptTemplate\n",
    "- Predict: ChatModel/LLM\n",
    "- Parse: OutputParser"
   ],
   "id": "46c78917f3223e51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "## Quick Start",
   "id": "fddbe24e2d8b0600"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## PromptTemplate",
   "id": "6c143496c16cc268"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3b6a36e4fa10ffc3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ChatModel",
   "id": "b06139ca93ad1fa4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9014d4dfc27b4aae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## OutputParser",
   "id": "a9fcf4254f1d12b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6f5d952544e1beb9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
