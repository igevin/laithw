{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ModelIO\n",
    "\n",
    "- Format: PromptTemplate\n",
    "- Predict: ChatModel/LLM\n",
    "- Parse: OutputParser"
   ],
   "id": "dbfa086c54461ff4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Quick Start\n",
    "\n",
    "æ ¸å¿ƒæ˜¯ï¼Œä¸‰ä¸ªæŠ½è±¡é€šè¿‡ `ï½œ` è¿æˆä¸€ä¸ªé“¾ï¼Œå¦‚ï¼š\n",
    "```\n",
    "chain = prompt | llm | parser\n",
    "res = chain.invoke()\n",
    "```\n",
    "\n",
    "é€šè¿‡ `invoke()` æ–¹æ³•è°ƒç”¨ chain æ—¶ï¼Œå‰ä¸€æ­¥çš„è¾“å‡ºä¼šæˆä¸ºåé¢çš„è¾“å…¥ï¼Œres çš„ç»“æœï¼Œä¸ºæœ€åä¸€æ­¥çš„è¾“å‡ºã€‚"
   ],
   "id": "749f246bf0d89b0d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T02:54:59.121448Z",
     "start_time": "2024-12-11T02:54:44.831106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "template = \"æ‹³å‡»æœ¯è¯­è§£é‡Šï¼š{name}\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"openai/gpt-4o-mini\")\n",
    "\n",
    "chain = prompt | llm\n",
    "# res = chain.invoke({\"name\": \"å·¦å‹¾æ‹³\"})\n",
    "res = chain.invoke(input={\"name\": \"å·¦å‹¾æ‹³\"})\n",
    "# è¿”å›ç»“æœä¸º `llm.invoke()` çš„ç»“æœï¼Œå³AIMessage\n",
    "print(res.content, \"\\n\", type(res), \"\\n\\n\")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "# å®Œæ•´çš„ chain ç”± prompt, llm, parser ä¸‰éƒ¨åˆ†æ„æˆï¼Œé€šè¿‡ç®¡é“ç¬¦ | è¿æ¥\n",
    "# è¿”å›ç»“æœä¸º parser çš„ç»“æœï¼Œå¦‚ä¸‹ï¼ŒStrOutputParserè¿”å›å­—ç¬¦ä¸²\n",
    "chain = prompt | llm | parser\n",
    "res = chain.invoke({\"name\": \"ä¸Šå‹¾æ‹³\"})\n",
    "print(res, \"\\n\", type(res))\n"
   ],
   "id": "cab3af4f509b863",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·¦å‹¾æ‹³ï¼ˆLeft Hookï¼‰æ˜¯æ‹³å‡»ä¸­çš„ä¸€ç§åŸºæœ¬æ”»å‡»æŠ€æ³•ï¼Œä¸»è¦ç”±å·¦æ‰‹å‘å‡ºã€‚å®ƒé€šå¸¸æ˜¯åœ¨å¯¹æ‰‹è·ç¦»è¾ƒè¿‘æ—¶ä½¿ç”¨ï¼Œæ—¨åœ¨æ”»å‡»å¯¹æ‰‹çš„å¤´éƒ¨æˆ–èº«ä½“ä¾§é¢ã€‚å·¦å‹¾æ‹³çš„ç‰¹ç‚¹æ˜¯ï¼š\n",
      "\n",
      "1. **å‘åŠ›æ–¹å¼**ï¼šå·¦å‹¾æ‹³çš„åŠ›é‡ä¸»è¦æ¥æºäºè‚©éƒ¨çš„æ—‹è½¬å’Œè…°éƒ¨çš„è½¬åŠ¨ï¼Œè€Œä¸ä»…ä»…æ˜¯æ‰‹è‡‚çš„åŠ›é‡ã€‚é€šè¿‡èº«ä½“çš„æ•´ä½“åè°ƒï¼Œå¯ä»¥äº§ç”Ÿæ›´å¼ºçš„æ‰“å‡»åŠ›åº¦ã€‚\n",
      "\n",
      "2. **æ”»å‡»è§’åº¦**ï¼šå·¦å‹¾æ‹³é€šå¸¸æ˜¯ä»¥å¼¯æ›²çš„æ‰‹è‡‚ä»ä¾§é¢å‘å‡ºï¼Œæ‹³å¤´çš„è½¨è¿¹å‘ˆå¼§å½¢ï¼Œç›®çš„æ˜¯ä»ä¾§é¢æ‰“å‡»å¯¹æ‰‹ï¼Œé¿å¼€å¯¹æ–¹çš„é˜²å®ˆã€‚\n",
      "\n",
      "3. **ä½¿ç”¨æ—¶æœº**ï¼šå·¦å‹¾æ‹³å¸¸ç”¨äºå¯¹æ‰‹å‡ºæ‹³åæˆ–åœ¨è¾ƒçŸ­è·ç¦»å†…è¿›è¡Œåå‡»ï¼Œå°¤å…¶æ˜¯åœ¨å¯¹æ‰‹çš„å¤´éƒ¨æˆ–ä¾§é¢æš´éœ²æ—¶ã€‚\n",
      "\n",
      "4. **é˜²å¾¡ä¸åå‡»**ï¼šæ–½å±•å·¦å‹¾æ‹³æ—¶ï¼Œæ‹³æ‰‹çš„å¦ä¸€åªæ‰‹è¦ä¿æŒåœ¨é˜²å®ˆä½ç½®ï¼Œä»¥ä¿æŠ¤è‡ªå·±å…å—å¯¹æ‰‹åå‡»ã€‚\n",
      "\n",
      "å·¦å‹¾æ‹³æ˜¯æ‹³å‡»æ‰‹éœ€è¦æŒæ¡çš„é‡è¦æŠ€æœ¯ä¹‹ä¸€ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å¢åŠ æ”»å‡»çš„å¤šæ ·æ€§å’Œå¨èƒæ€§ã€‚ \n",
      " <class 'langchain_core.messages.ai.AIMessage'> \n",
      "\n",
      "\n",
      "ä¸Šå‹¾æ‹³ï¼ˆUppercutï¼‰æ˜¯ä¸€ç§æ‹³å‡»æŠ€æœ¯ï¼Œä¸»è¦ç”¨äºè¿‘è·ç¦»æ”»å‡»å¯¹æ‰‹çš„ä¸‹å·´æˆ–é¢éƒ¨ã€‚å®ƒçš„ç‰¹ç‚¹æ˜¯æ‹³å¤´ä»ä¸‹å‘ä¸ŠæŒ¥å‡ºï¼Œé€šå¸¸æ˜¯ç”±è†ç›–å’Œè‡€éƒ¨çš„åŠ›é‡é©±åŠ¨ï¼Œä¼´éšç€èº«ä½“çš„æ—‹è½¬å’Œé‡å¿ƒçš„è½¬ç§»ã€‚\n",
      "\n",
      "ä¸Šå‹¾æ‹³çš„ä¸»è¦ç”¨é€”åŒ…æ‹¬ï¼š\n",
      "\n",
      "1. **æ‰“å‡»å¯¹æ‰‹çš„ä¸‹å·´**ï¼šä¸Šå‹¾æ‹³å¯ä»¥æœ‰æ•ˆåœ°æ‰“å‡»å¯¹æ‰‹çš„ä¸‹å·´ï¼Œä½¿å…¶å¤±å»å¹³è¡¡æˆ–é€ æˆæ˜æ˜¾çš„ä¼¤å®³ã€‚\n",
      "2. **åå‡»**ï¼šåœ¨å¯¹æ‰‹é è¿‘æ—¶ï¼Œä¸Šå‹¾æ‹³å¯ä»¥ä½œä¸ºæœ‰æ•ˆçš„åå‡»æ‰‹æ®µï¼Œç‰¹åˆ«æ˜¯åœ¨å¯¹æ‰‹è¿›è¡Œç›´æ‹³æˆ–ä¾§å‡»æ—¶ã€‚\n",
      "3. **çªç ´é˜²å®ˆ**ï¼šå¦‚æœå¯¹æ‰‹çš„æ‰‹è‡‚è¿‡äºé«˜æˆ–å°å µäº†ä¾§é¢ï¼Œä¸Šå‹¾æ‹³å¯ä»¥ç©¿è¿‡å¯¹æ‰‹çš„é˜²å®ˆã€‚\n",
      "\n",
      "æ–½å±•ä¸Šå‹¾æ‹³æ—¶ï¼Œæ‹³å‡»æ‰‹éœ€è¦æ³¨æ„ä¿æŒç¨³å®šçš„å§¿åŠ¿ï¼Œä»¥ç¡®ä¿åŠ›é‡çš„æœ‰æ•ˆä¼ é€’ï¼ŒåŒæ—¶é¿å…æš´éœ²è‡ªå·±ã€‚ä¸Šå‹¾æ‹³æ˜¯ä¸€é¡¹éœ€è¦æŠ€å·§å’Œæ—¶æœºçš„æŠ€æœ¯ï¼Œé€šå¸¸ä¸å…¶ä»–æ‹³å‡»ç»„åˆæŠ€é…åˆä½¿ç”¨ã€‚ \n",
      " <class 'str'>\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### PromptTemplate",
   "id": "3b5a9d764b542692"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T07:35:24.104297Z",
     "start_time": "2024-12-14T07:35:24.098829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"æ‹³å‡»æœ¯è¯­è§£é‡Šï¼š{name}\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# è¾“å‡ºç”Ÿæˆçš„æ–‡æœ¬\n",
    "res = prompt.format(name=\"å·¦å‹¾æ‹³\")\n",
    "print(res, \"\\n\", type(res), \"\\n\\n\")\n"
   ],
   "id": "9a679b621e7b733d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‹³å‡»æœ¯è¯­è§£é‡Šï¼šå·¦å‹¾æ‹³ \n",
      " <class 'str'> \n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T07:37:28.641214Z",
     "start_time": "2024-12-14T07:37:21.782813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"openai/gpt-4o-mini\")\n",
    "\n",
    "resp = chat.invoke(res)\n",
    "print(resp.content)"
   ],
   "id": "9d75497d4b8342c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·¦å‹¾æ‹³ï¼ˆLeft Hookï¼‰æ˜¯æ‹³å‡»ä¸­çš„ä¸€ç§åŸºæœ¬æ‹³æ³•ï¼Œé€šå¸¸ç”±å·¦æ‰‹å‘å‡ºã€‚å®ƒçš„ç‰¹ç‚¹æ˜¯æ‹³å¤´ä»¥å¼§å½¢è½¨è¿¹å‘ç›®æ ‡æ‰“å‡ºï¼Œä¸»è¦ç”¨äºæ”»å‡»å¯¹æ‰‹çš„ä¾§é¢ï¼Œå°¤å…¶æ˜¯å¤´éƒ¨å’Œè‚‹éƒ¨ã€‚å·¦å‹¾æ‹³çš„å‘åŠ›æ–¹å¼å¤šä¾èµ–äºè…°éƒ¨å’Œè‚©éƒ¨çš„æ—‹è½¬ï¼Œä»¥åŠé‡å¿ƒçš„è½¬ç§»ï¼Œä»¥å¢å¼ºåŠ›é‡å’Œé€Ÿåº¦ã€‚\n",
      "\n",
      "å·¦å‹¾æ‹³çš„ä½¿ç”¨åœºåˆé€šå¸¸æ˜¯åœ¨å¯¹æ‰‹é è¿‘æ—¶ï¼Œæˆ–è€…åœ¨ç»„åˆæ‹³ä¸­ä½œä¸ºä¸€ä¸ªåˆ‡å…¥çš„æ”»å‡»æ‰‹æ®µã€‚ç”±äºå…¶æ‰“å‡»è§’åº¦ç‹¬ç‰¹ï¼Œå·¦å‹¾æ‹³èƒ½å¤Ÿæœ‰æ•ˆåœ°çªç ´å¯¹æ‰‹çš„é˜²å®ˆï¼Œé€ æˆæ„æƒ³ä¸åˆ°çš„æ”»å‡»æ•ˆæœã€‚åœ¨å®æˆ˜ä¸­ï¼Œå·¦å‹¾æ‹³éœ€è¦ç²¾å‡†çš„æ—¶æœºå’Œè·ç¦»åˆ¤æ–­ï¼Œä»¥ç¡®ä¿èƒ½å¤Ÿæœ‰æ•ˆå‡»ä¸­ç›®æ ‡è€Œä¸è¢«å¯¹æ‰‹åå‡»ã€‚\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T07:48:16.559422Z",
     "start_time": "2024-12-14T07:48:16.554794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"æ‹³å‡»æœ¯è¯­è§£é‡Šï¼š{name}\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# è¾“å‡ºPromptValue å¯¹è±¡\n",
    "res = prompt.invoke({\"name\": \"å·¦ä¸Šå‹¾æ‹³\"})\n",
    "print(res, \"\\n\", type(res), \"\\n\")\n",
    "print(\" To string:\", res.to_string(), \"\\n\", \"To messages:\", res.to_messages())\n"
   ],
   "id": "250d16e899b64495",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='æ‹³å‡»æœ¯è¯­è§£é‡Šï¼šå·¦ä¸Šå‹¾æ‹³' \n",
      " <class 'langchain_core.prompt_values.StringPromptValue'> \n",
      "\n",
      " To string: æ‹³å‡»æœ¯è¯­è§£é‡Šï¼šå·¦ä¸Šå‹¾æ‹³ \n",
      " To messages: [HumanMessage(content='æ‹³å‡»æœ¯è¯­è§£é‡Šï¼šå·¦ä¸Šå‹¾æ‹³', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T07:50:14.114126Z",
     "start_time": "2024-12-14T07:50:06.099372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"openai/gpt-4o-mini\")\n",
    "\n",
    "resp = chat.invoke(res)\n",
    "print(resp.content)"
   ],
   "id": "3c9ac249da8a6baa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·¦ä¸Šå‹¾æ‹³ï¼ˆLeft Uppercutï¼‰æ˜¯æ‹³å‡»ä¸­çš„ä¸€ç§æ”»å‡»æ€§æ‹³æ³•ï¼Œä¸»è¦ç”¨äºæ‰“å‡»å¯¹æ‰‹çš„ä¸‹å·´æˆ–é¢éƒ¨ã€‚å®ƒçš„ç‰¹ç‚¹æ˜¯æ‹³å¤´ä»ä¸‹å‘ä¸Šæ–œå‘å‰æ–¹æŒ¥å‡ºï¼Œé€šå¸¸æ˜¯åœ¨ä¸å¯¹æ‰‹è¾ƒè¿‘çš„è·ç¦»ä¸‹æ–½å±•ã€‚\n",
      "\n",
      "### å…·ä½“ç‰¹ç‚¹ï¼š\n",
      "\n",
      "1. **å‡ºæ‹³è§’åº¦**ï¼šå·¦ä¸Šå‹¾æ‹³çš„å‡ºæ‹³è§’åº¦è¾ƒä½ï¼Œæ‹³å¤´ä»è…°éƒ¨æˆ–èƒ¸éƒ¨ä½ç½®å‘ä¸ŠæŒ¥å‡ºï¼Œå½¢æˆä¸€ä¸ªå¼§å½¢è½¨è¿¹ã€‚\n",
      "  \n",
      "2. **ç›®æ ‡**ï¼šä¸»è¦ç›®æ ‡æ˜¯å¯¹æ‰‹çš„ä¸‹å·´ã€é¢šéƒ¨æˆ–è„¸éƒ¨ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°é€ æˆæ‰“å‡»å’Œå‡»å€’ã€‚\n",
      "\n",
      "3. **ä½¿ç”¨æ—¶æœº**ï¼šé€šå¸¸åœ¨å¯¹æ‰‹çš„é˜²å®ˆè¾ƒä¸ºæ¾æ‡ˆæˆ–åœ¨å¯¹æ‰‹è¿›æ”»æ—¶ï¼Œåˆ©ç”¨å¯¹æ–¹çš„é‡å¿ƒå‘å‰çš„æœºä¼šè¿›è¡Œæ”»å‡»ã€‚\n",
      "\n",
      "4. **åŠ›é‡æ¥æº**ï¼šå·¦ä¸Šå‹¾æ‹³çš„åŠ›é‡æ¥è‡ªäºè…¿éƒ¨ã€è…°éƒ¨çš„æ—‹è½¬å’Œè‚©éƒ¨çš„å‘åŠ›ï¼Œé…åˆæ‰‹è‡‚çš„æŒ¥åŠ¨ï¼Œä½¿å‡ºæ‹³æ›´åŠ æœ‰åŠ›ã€‚\n",
      "\n",
      "5. **é˜²å®ˆåå‡»**ï¼šå·¦ä¸Šå‹¾æ‹³ä¹Ÿå¸¸ç”¨äºåå‡»ï¼Œå°¤å…¶æ˜¯åœ¨å¯¹æ‰‹è¯•å›¾é è¿‘æ—¶ï¼Œå¯ä»¥åˆ©ç”¨å…¶å‘åŠ›çš„åŒæ—¶ä¿æŠ¤è‡ªå·±ã€‚\n",
      "\n",
      "å·¦ä¸Šå‹¾æ‹³æ˜¯æ‹³å‡»æ‰‹åœ¨æ¯”èµ›ä¸­å¸¸ç”¨çš„ä¸€ç§æŠ€æœ¯ï¼Œå¯¹äºæé«˜æ‰“å‡»æ•ˆæœå’Œå¢åŠ æ¯”èµ›èƒœç®—éƒ½æœ‰é‡è¦ä½œç”¨ã€‚\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ChatPromptTemplate",
   "id": "39cb29e8fac0a492"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T09:01:44.270804Z",
     "start_time": "2024-12-12T09:01:44.267425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"æ‹³å‡»æœ¯è¯­è§£é‡Šï¼š{name}\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# è¾“å‡ºç”Ÿæˆçš„æ–‡æœ¬\n",
    "res = prompt.format(name=\"å·¦å‹¾æ‹³\")\n",
    "print(res, \"\\n\", type(res), \"\\n\\n\")\n",
    "\n",
    "# è¾“å‡ºPromptValue å¯¹è±¡\n",
    "res = prompt.invoke({\"name\": \"å·¦å‹¾æ‹³\"})\n",
    "print(res, \"\\n\", type(res), \"\\n\\n\")\n",
    "print(res.to_string(), \"\\n\", type(res.to_string()))\n",
    "print(res.to_messages(), \"\\n\", type(res.to_messages()))"
   ],
   "id": "a1b9c5e16ebdbf89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: æ‹³å‡»æœ¯è¯­è§£é‡Šï¼šå·¦å‹¾æ‹³ \n",
      " <class 'str'> \n",
      "\n",
      "\n",
      "messages=[HumanMessage(content='æ‹³å‡»æœ¯è¯­è§£é‡Šï¼šå·¦å‹¾æ‹³', additional_kwargs={}, response_metadata={})] \n",
      " <class 'langchain_core.prompt_values.ChatPromptValue'> \n",
      "\n",
      "\n",
      "Human: æ‹³å‡»æœ¯è¯­è§£é‡Šï¼šå·¦å‹¾æ‹³ \n",
      " <class 'str'>\n",
      "[HumanMessage(content='æ‹³å‡»æœ¯è¯­è§£é‡Šï¼šå·¦å‹¾æ‹³', additional_kwargs={}, response_metadata={})] \n",
      " <class 'list'>\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T06:30:48.626721Z",
     "start_time": "2024-12-11T06:30:48.620366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "    (\"human\", \"Hello, how are you doing?\"),\n",
    "    (\"ai\", \"I'm doing well, thanks!\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "prompt = template.invoke(\n",
    "    {\n",
    "        \"name\": \"Bob\",\n",
    "        \"user_input\": \"What is your name?\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(prompt, \"\\n\", prompt.to_messages(), \"\\n\", type(prompt), \"\\n\\n\")\n",
    "\n",
    "template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful AI bot.\"),\n",
    "    # Means the template will receive an optional list of messages under\n",
    "    # the \"conversation\" key\n",
    "    (\"placeholder\", \"{conversation}\")\n",
    "    # Equivalently:\n",
    "    # MessagesPlaceholder(variable_name=\"conversation\", optional=True)\n",
    "])\n",
    "\n",
    "prompt = template.invoke(\n",
    "    {\n",
    "        \"conversation\": [\n",
    "            (\"human\", \"Hi!\"),\n",
    "            (\"ai\", \"How can I assist you today?\"),\n",
    "            (\"human\", \"Can you make me an ice cream sundae?\"),\n",
    "            (\"ai\", \"No.\")\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(prompt, \"\\n\", prompt.to_messages(), \"\\n\", type(prompt))\n"
   ],
   "id": "ab4df2e5f786554b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful AI bot. Your name is Bob.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how are you doing?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm doing well, thanks!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is your name?', additional_kwargs={}, response_metadata={})] \n",
      " [SystemMessage(content='You are a helpful AI bot. Your name is Bob.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how are you doing?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm doing well, thanks!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is your name?', additional_kwargs={}, response_metadata={})] \n",
      " <class 'langchain_core.prompt_values.ChatPromptValue'> \n",
      "\n",
      "\n",
      "messages=[SystemMessage(content='You are a helpful AI bot.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}), AIMessage(content='How can I assist you today?', additional_kwargs={}, response_metadata={}), HumanMessage(content='Can you make me an ice cream sundae?', additional_kwargs={}, response_metadata={}), AIMessage(content='No.', additional_kwargs={}, response_metadata={})] \n",
      " [SystemMessage(content='You are a helpful AI bot.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}), AIMessage(content='How can I assist you today?', additional_kwargs={}, response_metadata={}), HumanMessage(content='Can you make me an ice cream sundae?', additional_kwargs={}, response_metadata={}), AIMessage(content='No.', additional_kwargs={}, response_metadata={})] \n",
      " <class 'langchain_core.prompt_values.ChatPromptValue'>\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T08:16:44.021173Z",
     "start_time": "2024-12-14T08:16:44.016422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "    (\"human\", \"Hello, how are you doing?\"),\n",
    "    (\"ai\", \"I'm doing well, thanks!\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "]\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(messages)\n",
    "prompt = template.invoke({\"name\": \"Bob\", \"user_input\": \"What is your name?\"})\n",
    "print(prompt.to_messages(), \"\\n\", type(prompt), \"\\n\\n\")\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful AI bot.\"),\n",
    "    (\"human\", \"Hello, how are you doing?\"),\n",
    "    (\"assistant\", \"I'm doing well, thanks!\"),\n",
    "    (\"user\", \"What's your name?\"),\n",
    "]\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(messages)\n",
    "prompt = template.invoke({})\n",
    "print(prompt.to_messages(), \"\\n\", type(prompt), \"\\n\\n\")\n",
    "\n"
   ],
   "id": "a4163388a6c52c55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful AI bot. Your name is Bob.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how are you doing?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm doing well, thanks!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is your name?', additional_kwargs={}, response_metadata={})] \n",
      " <class 'langchain_core.prompt_values.ChatPromptValue'> \n",
      "\n",
      "\n",
      "[SystemMessage(content='You are a helpful AI bot.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how are you doing?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm doing well, thanks!\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"What's your name?\", additional_kwargs={}, response_metadata={})] \n",
      " <class 'langchain_core.prompt_values.ChatPromptValue'> \n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T08:05:54.077709Z",
     "start_time": "2024-12-14T08:05:51.059697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ä½ æ˜¯ä¸€ä¸ªä¼˜ç§€çš„ç¿»è¯‘ä¸“å®¶ï¼Œéå¸¸æ“…é•¿æŠŠä¸­æ–‡ç¿»è¯‘ä¸º{language}\"),\n",
    "        (\"user\", \"{text}\")\n",
    "    ]\n",
    ")\n",
    "prompt = prompt_template.invoke({\"language\": \"è‹±æ–‡\", \"text\": \"æ¬¢è¿ä½¿ç”¨ Langchain è¿›è¡Œå¤§æ¨¡å‹å¼€å‘\"})\n",
    "print(prompt.to_messages(), \"\\n\", type(prompt), \"\\n\")\n",
    "print(prompt_template.format(language=\"è‹±æ–‡\", text=\"æ¬¢è¿ä½¿ç”¨ Langchain è¿›è¡Œå¤§æ¨¡å‹å¼€å‘\"), \"\\n\\n\")\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"openai/gpt-4o-mini\")\n",
    "resp = chat.invoke(prompt)\n",
    "print(resp.content)\n"
   ],
   "id": "7cc3568d208eb9f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='ä½ æ˜¯ä¸€ä¸ªä¼˜ç§€çš„ç¿»è¯‘ä¸“å®¶ï¼Œéå¸¸æ“…é•¿æŠŠä¸­æ–‡ç¿»è¯‘ä¸ºè‹±æ–‡', additional_kwargs={}, response_metadata={}), HumanMessage(content='æ¬¢è¿ä½¿ç”¨ Langchain è¿›è¡Œå¤§æ¨¡å‹å¼€å‘', additional_kwargs={}, response_metadata={})] \n",
      " <class 'langchain_core.prompt_values.ChatPromptValue'> \n",
      "\n",
      "System: ä½ æ˜¯ä¸€ä¸ªä¼˜ç§€çš„ç¿»è¯‘ä¸“å®¶ï¼Œéå¸¸æ“…é•¿æŠŠä¸­æ–‡ç¿»è¯‘ä¸ºè‹±æ–‡\n",
      "Human: æ¬¢è¿ä½¿ç”¨ Langchain è¿›è¡Œå¤§æ¨¡å‹å¼€å‘ \n",
      "\n",
      "\n",
      "Welcome to using Langchain for large model development!\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ChatModel/LLM",
   "id": "f76f6b13f88fcb8e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T07:37:16.936156Z",
     "start_time": "2024-12-11T07:37:05.324971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "template = \"æ‹³å‡»æœ¯è¯­è§£é‡Šï¼š{name}\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# ç”Ÿæˆæ–‡æœ¬æ¶ˆæ¯\n",
    "msg = prompt.format(name=\"äº¤å‰æ‹³\")\n",
    "# åˆ›å»º PromptValue å¯¹è±¡\n",
    "prompt_value = prompt.invoke({\"name\": \"ç›´æ‹³\"})\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"openai/gpt-4o-mini\")\n",
    "\n",
    "# æ–‡æœ¬æ¶ˆæ¯æ–¹å¼è°ƒç”¨\n",
    "res = chat.invoke(msg)\n",
    "print(res.content)\n",
    "\n",
    "# prompt value æ–¹å¼è°ƒç”¨\n",
    "res = chat.invoke(prompt_value)\n",
    "print(res.content)\n",
    "\n",
    "# é“¾å¼è°ƒç”¨\n",
    "chain = prompt | chat\n",
    "res = chain.invoke({\"name\": \"åˆºæ‹³\"})\n",
    "print(res.content)"
   ],
   "id": "d2ee209c62091a3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "äº¤å‰æ‹³ï¼ˆCrossï¼‰æ˜¯æ‹³å‡»ä¸­çš„ä¸€ç§åŸºæœ¬æ”»å‡»æŠ€æœ¯ï¼Œé€šå¸¸æŒ‡çš„æ˜¯ä½¿ç”¨ä¸»æ‰‹ï¼ˆå¯¹äºå³æ‰‹æ‹³å‡»æ‰‹è€Œè¨€æ˜¯å³æ‰‹ï¼Œå¯¹äºå·¦æ‰‹æ‹³å‡»æ‰‹è€Œè¨€æ˜¯å·¦æ‰‹ï¼‰ä»ä¸€ä¾§æ¨ªå‘æ‰“å‘å¯¹æ‰‹çš„æ‹³å¤´ã€‚äº¤å‰æ‹³çš„ç‰¹ç‚¹æ˜¯åŠ›é‡å¤§ã€é€Ÿåº¦å¿«ï¼Œé€šå¸¸åœ¨å¯¹æ‰‹å‡ºæ‹³æˆ–é˜²å®ˆæ—¶çš„ç©ºæ¡£ä¸­ä½¿ç”¨ã€‚\n",
      "\n",
      "äº¤å‰æ‹³çš„å‘åŠ›æ–¹å¼ä¸€èˆ¬æ˜¯é€šè¿‡è½¬åŠ¨èº«ä½“ã€è‚©è†€å’Œè‡€éƒ¨æ¥å¢åŠ åŠ›é‡ï¼ŒåŒæ—¶é…åˆè„šæ­¥ç§»åŠ¨ä½¿å¾—æ”»å‡»æ›´åŠ çµæ´»å’Œå…·æœ‰å¨èƒæ€§ã€‚äº¤å‰æ‹³çš„æœ‰æ•ˆæ€§åœ¨äºå®ƒèƒ½å¤Ÿçªç ´å¯¹æ–¹çš„é˜²å®ˆï¼Œç›´æ¥å‡»ä¸­å¯¹æ‰‹çš„é¢éƒ¨æˆ–èº«ä½“éƒ¨ä½ã€‚\n",
      "\n",
      "åœ¨è®­ç»ƒä¸­ï¼Œæ‹³å‡»æ‰‹é€šå¸¸ä¼šç»ƒä¹ äº¤å‰æ‹³çš„å‘åŠ›ã€å‡†ç¡®æ€§ä»¥åŠä¸å…¶ä»–æ‹³å‡»æŠ€æœ¯çš„ç»“åˆä½¿ç”¨ï¼Œä»¥æé«˜æ•´ä½“çš„æ”»å‡»èƒ½åŠ›å’Œæˆ˜æœ¯æ°´å¹³ã€‚\n",
      "ç›´æ‹³æ˜¯æ‹³å‡»ä¸­ä¸€ç§åŸºæœ¬çš„å‡»æ‰“æ–¹å¼ï¼Œé€šå¸¸ç”¨å‰æ‰‹ï¼ˆä¸»æ‰‹æˆ–éä¸»æ‰‹ï¼‰ç›´æ¥å‘å¯¹æ‰‹çš„é¢éƒ¨æˆ–èº«ä½“å‘å‡ºæ”»å‡»ã€‚ç›´æ‹³çš„ç‰¹ç‚¹æ˜¯æ‰“å‡»è½¨è¿¹ç¬”ç›´ï¼Œé€Ÿåº¦å¿«ï¼ŒåŠ›é‡é›†ä¸­ã€‚ç”±äºå…¶å‡ºæ‹³æ–¹å¼ç®€å•æœ‰æ•ˆï¼Œç›´æ‹³è¢«å¹¿æ³›åº”ç”¨äºæ‹³å‡»æ¯”èµ›å’Œè®­ç»ƒä¸­ã€‚\n",
      "\n",
      "ç›´æ‹³çš„ä¸»è¦ä¼˜ç‚¹åŒ…æ‹¬ï¼š\n",
      "\n",
      "1. **é€Ÿåº¦å¿«**ï¼šç”±äºå‡ºæ‹³è½¨è¿¹çŸ­ï¼Œç›´æ‹³å¯ä»¥è¿…é€Ÿå‡»ä¸­ç›®æ ‡ã€‚\n",
      "2. **æ˜“äºæ§åˆ¶**ï¼šç›´æ‹³çš„å‘åŠ›æ–¹å¼ç›¸å¯¹ç®€å•ï¼Œæ‹³æ‰‹å¯ä»¥è¾ƒå¥½åœ°æ§åˆ¶å‡ºæ‹³çš„åŠ›é‡å’Œæ–¹å‘ã€‚\n",
      "3. **é˜²å®ˆèƒ½åŠ›**ï¼šåœ¨å‡ºæ‹³çš„åŒæ—¶ï¼Œæ‹³å‡»æ‰‹å¯ä»¥ä¿æŒé˜²å®ˆå§¿åŠ¿ï¼Œå‡å°‘è¢«åå‡»çš„é£é™©ã€‚\n",
      "\n",
      "ç›´æ‹³å¯ä»¥åˆ†ä¸ºå·¦ç›´æ‹³ï¼ˆé€šå¸¸æ˜¯å³æ‰‹ä¸»æ‹³æ‰‹çš„å‰æ‰‹ï¼‰å’Œå³ç›´æ‹³ï¼ˆä¸»æ‹³æ‰‹çš„åæ‰‹ï¼‰ï¼Œæ ¹æ®æ‹³æ‰‹çš„ç«™ä½å’Œä¸»æ‰‹çš„ä¸åŒè€Œæœ‰æ‰€åŒºåˆ«ã€‚\n",
      "åˆºæ‹³ï¼ˆJabï¼‰æ˜¯æ‹³å‡»ä¸­ä¸€ç§åŸºç¡€ä¸”é‡è¦çš„æ”»å‡»æŠ€æ³•ã€‚å®ƒé€šå¸¸æ˜¯ç”¨å‰æ‰‹ï¼ˆå³å·¦æ‰‹å¯¹äºå³æ‰‹æ‹³å‡»æ‰‹ï¼Œå³æ‰‹å¯¹äºå·¦æ‰‹æ‹³å‡»æ‰‹ï¼‰å¿«é€Ÿã€ç›´çº¿åœ°å‘å¯¹æ‰‹çš„é¢éƒ¨æˆ–èº«ä½“å‘å‡ºçš„æ‹³å¤´ã€‚åˆºæ‹³çš„ä¸»è¦ç‰¹ç‚¹åŒ…æ‹¬ï¼š\n",
      "\n",
      "1. **é€Ÿåº¦**ï¼šåˆºæ‹³é€Ÿåº¦å¿«ï¼Œèƒ½å¤Ÿå¿«é€Ÿå‡ºå‡»å¹¶æ’¤å›ï¼Œç»™å¯¹æ‰‹é€ æˆå‹åŠ›ã€‚\n",
      "2. **è·ç¦»æ§åˆ¶**ï¼šåˆºæ‹³å¯ä»¥ç”¨æ¥ä¿æŒä¸å¯¹æ‰‹çš„è·ç¦»ï¼Œå¸®åŠ©æ‹³æ‰‹è¯„ä¼°å¯¹æ‰‹çš„ååº”ã€‚\n",
      "3. **çªç ´é˜²å®ˆ**ï¼šåˆºæ‹³å¯ä»¥ç”¨æ¥æ‰“ç ´å¯¹æ‰‹çš„é˜²å®ˆï¼Œåˆ›é€ å‡ºè¿›æ”»çš„æœºä¼šã€‚\n",
      "4. **ç»„åˆè¿›æ”»**ï¼šåˆºæ‹³é€šå¸¸ä½œä¸ºç»„åˆæ‹³çš„å¼€ç«¯ï¼Œä¹‹åå¯ä»¥æ¥ä¸Šå…¶ä»–æ›´æœ‰åŠ›çš„æ”»å‡»ã€‚\n",
      "\n",
      "åœ¨æ¯”èµ›ä¸­ï¼Œåˆºæ‹³ä¸ä»…ç”¨äºè¿›æ”»ï¼Œè¿˜å¯ä»¥ç”¨æ¥æ¶ˆè€—å¯¹æ‰‹çš„ä½“åŠ›å’Œå¯»æ‰¾è¿›æ”»çš„æœºä¼šï¼Œæ˜¯æ‹³æ‰‹å¿…å¤‡çš„åŸºæœ¬æŠ€èƒ½ä¹‹ä¸€ã€‚\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T08:03:36.213505Z",
     "start_time": "2024-12-11T08:03:25.853427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "msgs = [\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä¸ªæœ‰æ°§æ‹³å‡»æ•™ç»ƒ\"),\n",
    "    (\"human\", \"è¯·å¸®æˆ‘è§£é‡Šæ‹³å‡»æœ¯è¯­ï¼Œå¦‚æœæœ¯è¯­æ˜¯è‹±æ–‡ï¼Œè¯·é¡ºä¾¿ç¿»è¯‘ï¼š{name}\")\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(msgs)\n",
    "chat = ChatOpenAI(model_name=\"openai/gpt-4o-mini\")\n",
    "\n",
    "# print(prompt.format(name=\"duck\"))\n",
    "# print(prompt.format_messages(name=\"duck\"))\n",
    "\n",
    "res = chat.invoke(prompt.format_messages(name=\"duck\"))\n",
    "print(res.content, \"\\n\")\n",
    "\n",
    "res = chat.invoke(prompt.invoke({\"name\": \"Slip\"}))\n",
    "print(res.content, \"\\n\")\n",
    "\n",
    "chain = prompt | chat\n",
    "res = chain.invoke({\"name\": \"weave\"})\n",
    "print(res.content, \"\\n\")\n"
   ],
   "id": "bad65e492a3fd6f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åœ¨æ‹³å‡»ä¸­ï¼Œâ€œduckâ€æŒ‡çš„æ˜¯ä¸€ç§èº²é¿å¯¹æ‰‹æ”»å‡»çš„æŠ€å·§ï¼Œå…·ä½“æ¥è¯´å°±æ˜¯å°†å¤´éƒ¨å‘ä¸‹å’Œå‘å‰ç§»åŠ¨ï¼Œä»¥é¿å¼€å³å°†æ¥çš„æ‹³å¤´ã€‚è¿™ä¸ªåŠ¨ä½œé€šå¸¸æ˜¯åœ¨å¯¹æ‰‹å‡ºæ‹³çš„ç¬é—´è¿›è¡Œï¼Œå¯ä»¥å¸®åŠ©æ‹³å‡»æ‰‹é¿å…è¢«å‡»ä¸­ï¼ŒåŒæ—¶ä¹Ÿä¸ºåå‡»æä¾›æœºä¼šã€‚\n",
      "\n",
      "ç®€è€Œè¨€ä¹‹ï¼Œâ€œduckâ€å°±æ˜¯â€œä½å¤´èº²é¿â€çš„æ„æ€ã€‚ \n",
      "\n",
      "â€œSlipâ€æ˜¯æ‹³å‡»ä¸­çš„ä¸€ä¸ªæœ¯è¯­ï¼Œä¸­æ–‡ç¿»è¯‘ä¸ºâ€œä¾§æ»‘â€ã€‚å®ƒæŒ‡çš„æ˜¯ä¸€ç§é˜²å®ˆæŠ€å·§ï¼Œæ‹³å‡»æ‰‹é€šè¿‡å¿«é€Ÿç§»åŠ¨å¤´éƒ¨å’Œèº«ä½“æ¥èº²é¿å¯¹æ‰‹çš„æ‹³å‡»ï¼Œè€Œä¸æ˜¯ç›´æ¥ç”¨æ‰‹è‡‚æŒ¡ä½ã€‚é€šè¿‡ä¾§æ»‘ï¼Œæ‹³å‡»æ‰‹å¯ä»¥ä¿æŒçµæ´»æ€§ï¼Œå¹¶ä¸ºåå‡»åˆ›é€ æœºä¼šã€‚è¿™ç§æŠ€å·§éœ€è¦è‰¯å¥½çš„å¹³è¡¡å’Œæ—¶æœºæŒæ¡ï¼Œä»¥é¿å…è¢«å‡»ä¸­ï¼ŒåŒæ—¶ä¿æŒæ”»å‡»çš„å‡†å¤‡çŠ¶æ€ã€‚ \n",
      "\n",
      "â€œweaveâ€åœ¨æ‹³å‡»ä¸­æŒ‡çš„æ˜¯ä¸€ç§èº²é¿æ”»å‡»çš„æŠ€å·§ï¼Œä¸­æ–‡ç¿»è¯‘ä¸ºâ€œæ‘‡æ‘†â€æˆ–â€œæ‰­åŠ¨â€ã€‚è¿™ç§æŠ€å·§é€šå¸¸ç”¨äºèº²é¿å¯¹æ‰‹çš„ç›´æ‹³æˆ–é’©æ‹³ï¼Œé€šè¿‡èº«ä½“çš„çµæ´»ç§»åŠ¨æ¥é¿å…è¢«å‡»ä¸­ã€‚æ‹³å‡»æ‰‹åœ¨è¿›è¡Œâ€œweaveâ€æ—¶ï¼Œä¼šé€šè¿‡å¼¯æ›²è†ç›–å’Œæ‰­åŠ¨èº«ä½“ï¼Œå‘ä¸€ä¾§æˆ–å¦ä¸€ä¾§ç§»åŠ¨å¤´éƒ¨ï¼Œä»è€Œä½¿æ”»å‡»è€…çš„æ‹³å¤´æ“¦è¿‡ä»–ä»¬çš„èº«ä½“ã€‚è¿™ä¸ªæŠ€å·§å¯ä»¥å¸®åŠ©æ‹³å‡»æ‰‹ä¿æŒé˜²å®ˆçš„åŒæ—¶å‡†å¤‡åå‡»ã€‚ \n",
      "\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T08:51:45.631143Z",
     "start_time": "2024-12-14T08:51:41.365983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from langchain_huggingface import HuggingFacePipeline, ChatHuggingFace\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# åˆ›å»ºå¤§æ¨¡å‹å¯¹è±¡\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"Qwen/Qwen2.5-0.5B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    device=device,\n",
    "    pipeline_kwargs=dict(\n",
    "        max_new_tokens=512,\n",
    "        return_full_text=False,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# åŸºäºå¤§æ¨¡å‹å¯¹è±¡ï¼Œåˆ›å»º ChatModel\n",
    "chat_model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "result = chat_model.invoke(\"å†™ä¸€é¦–å…³äºè¥¿æ¹–æ–­æ¡¥æ®‹é›ªçš„ä¸ƒè¨€ç»å¥ã€‚\")\n",
    "print(result.content)"
   ],
   "id": "3b293bfbe0712970",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ–­æ¡¥æ®‹é›ªæ˜ å­¤å³°ï¼Œç‹¬æ­¥å¯’æ—æ¢¦é‡Œæ¸¸ã€‚\n",
      "ä¸€ç¼•æ¸…é£æ¥ä½•å¤„ï¼Ÿä¸çŸ¥ä»Šå¤•å‡ æ—¶ä¼‘ã€‚\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## OutputParser",
   "id": "edd4abc187305ec6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T08:12:42.697352Z",
     "start_time": "2024-12-11T08:12:42.694559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "output = parser.invoke(res)\n",
    "print(output, \"\\n\", type(output))\n",
    "\n",
    "\n"
   ],
   "id": "b2b6ffe2f747e410",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€œweaveâ€åœ¨æ‹³å‡»ä¸­æŒ‡çš„æ˜¯ä¸€ç§èº²é¿æ”»å‡»çš„æŠ€å·§ï¼Œä¸­æ–‡ç¿»è¯‘ä¸ºâ€œæ‘‡æ‘†â€æˆ–â€œæ‰­åŠ¨â€ã€‚è¿™ç§æŠ€å·§é€šå¸¸ç”¨äºèº²é¿å¯¹æ‰‹çš„ç›´æ‹³æˆ–é’©æ‹³ï¼Œé€šè¿‡èº«ä½“çš„çµæ´»ç§»åŠ¨æ¥é¿å…è¢«å‡»ä¸­ã€‚æ‹³å‡»æ‰‹åœ¨è¿›è¡Œâ€œweaveâ€æ—¶ï¼Œä¼šé€šè¿‡å¼¯æ›²è†ç›–å’Œæ‰­åŠ¨èº«ä½“ï¼Œå‘ä¸€ä¾§æˆ–å¦ä¸€ä¾§ç§»åŠ¨å¤´éƒ¨ï¼Œä»è€Œä½¿æ”»å‡»è€…çš„æ‹³å¤´æ“¦è¿‡ä»–ä»¬çš„èº«ä½“ã€‚è¿™ä¸ªæŠ€å·§å¯ä»¥å¸®åŠ©æ‹³å‡»æ‰‹ä¿æŒé˜²å®ˆçš„åŒæ—¶å‡†å¤‡åå‡»ã€‚ \n",
      " <class 'str'>\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_openai import ChatOpenAI\n",
    "#\n",
    "# msgs = [\n",
    "#     (\"system\", \"You extract email addresses into JSON data.\"),\n",
    "#     (\"human\", \"Feeling stuck? Send a message to help@mycompany.com.\")\n",
    "# ]\n",
    "#\n",
    "# prompt = ChatPromptTemplate.from_messages(msgs)\n",
    "# chat = ChatOpenAI(model_name=\"openai/gpt-4o-mini\")\n",
    "#\n",
    "# chain = prompt | chat\n",
    "# res = chain.invoke({})\n",
    "# print(res.content, \"\\n\")"
   ],
   "id": "3121df6768445f0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:08:32.532628Z",
     "start_time": "2024-12-11T09:08:29.554699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "structured_parser = StructuredOutputParser.from_response_schemas(\n",
    "    [\n",
    "        ResponseSchema(name=\"terminology\", description=\"ä¸­æ–‡æœ¯è¯­åç§°\"),\n",
    "        ResponseSchema(name=\"explanation\", description=\"æœ¯è¯­çš„è§£é‡Š\")\n",
    "    ]\n",
    ")\n",
    "response_format_instructions = structured_parser.get_format_instructions()\n",
    "\n",
    "msgs = [\n",
    "    (\n",
    "    \"system\", \"ä½ æ˜¯ä¸€ä¸ªæœ‰æ°§æ‹³å‡»æ•™ç»ƒï¼Œè¯·å¸®æˆ‘è§£é‡Šæ‹³å‡»æœ¯è¯­ï¼Œå¦‚æœæœ¯è¯­æ˜¯è‹±æ–‡ï¼Œè¯·ç¿»è¯‘ä¸ºä¸­æ–‡æœ¯è¯­ã€‚{response_format_instructions}\"),\n",
    "    (\"human\", \"æœ¯è¯­ï¼š{name}\")\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(msgs).partial(response_format_instructions=response_format_instructions)\n",
    "print(prompt, \"\\n\")\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "chain = prompt | chat\n",
    "\n",
    "# res = chain.invoke({\"name\": \"Overhand\", \"response_format_instructions\": response_format_instructions})\n",
    "res = chain.invoke({\"name\": \"Overhand\"})\n",
    "print(res, \"\\n\")\n",
    "\n",
    "structured_output = structured_parser.invoke(res)\n",
    "print(structured_output, \"\\n\", type(structured_output), \"\\n\")\n",
    "structured_output = structured_parser.parse(res.content)\n",
    "print(structured_output, \"\\n\", type(structured_output))\n",
    "\n"
   ],
   "id": "b044445dd941368c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['name'] input_types={} partial_variables={'response_format_instructions': 'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"terminology\": string  // ä¸­æ–‡æœ¯è¯­åç§°\\n\\t\"explanation\": string  // æœ¯è¯­çš„è§£é‡Š\\n}\\n```'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['response_format_instructions'], input_types={}, partial_variables={}, template='ä½ æ˜¯ä¸€ä¸ªæœ‰æ°§æ‹³å‡»æ•™ç»ƒï¼Œè¯·å¸®æˆ‘è§£é‡Šæ‹³å‡»æœ¯è¯­ï¼Œå¦‚æœæœ¯è¯­æ˜¯è‹±æ–‡ï¼Œè¯·ç¿»è¯‘ä¸ºä¸­æ–‡æœ¯è¯­ã€‚{response_format_instructions}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['name'], input_types={}, partial_variables={}, template='æœ¯è¯­ï¼š{name}'), additional_kwargs={})] \n",
      "\n",
      "content='```json\\n{\\n\\t\"terminology\": \"è¿‡é¡¶æ‹³\",\\n\\t\"explanation\": \"è¿‡é¡¶æ‹³æ˜¯ä¸€ç§ä»é«˜å¤„å‘ä¸‹æ‰“å‡ºçš„æ‹³å‡»åŠ¨ä½œï¼Œé€šå¸¸æ˜¯ä»¥å¼§å½¢è½¨è¿¹å‡»æ‰“å¯¹æ‰‹çš„å¤´éƒ¨æˆ–èº«ä½“ã€‚è¿™ç§æ‹³æ³•å¯ä»¥åœ¨å¯¹æ‰‹ä½å¤´æˆ–è€…é˜²å®ˆæ—¶æœ‰æ•ˆåœ°çªç ´ä»–ä»¬çš„é˜²çº¿ã€‚\"\\n}\\n```' additional_kwargs={'refusal': ''} response_metadata={'token_usage': {'completion_tokens': 78, 'prompt_tokens': 106, 'total_tokens': 184, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'openai/gpt-4o-mini', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None} id='run-f8756d6b-f28a-454f-a70d-f458d4ab6268-0' usage_metadata={'input_tokens': 106, 'output_tokens': 78, 'total_tokens': 184, 'input_token_details': {}, 'output_token_details': {}} \n",
      "\n",
      "{'terminology': 'è¿‡é¡¶æ‹³', 'explanation': 'è¿‡é¡¶æ‹³æ˜¯ä¸€ç§ä»é«˜å¤„å‘ä¸‹æ‰“å‡ºçš„æ‹³å‡»åŠ¨ä½œï¼Œé€šå¸¸æ˜¯ä»¥å¼§å½¢è½¨è¿¹å‡»æ‰“å¯¹æ‰‹çš„å¤´éƒ¨æˆ–èº«ä½“ã€‚è¿™ç§æ‹³æ³•å¯ä»¥åœ¨å¯¹æ‰‹ä½å¤´æˆ–è€…é˜²å®ˆæ—¶æœ‰æ•ˆåœ°çªç ´ä»–ä»¬çš„é˜²çº¿ã€‚'} \n",
      " <class 'dict'> \n",
      "\n",
      "{'terminology': 'è¿‡é¡¶æ‹³', 'explanation': 'è¿‡é¡¶æ‹³æ˜¯ä¸€ç§ä»é«˜å¤„å‘ä¸‹æ‰“å‡ºçš„æ‹³å‡»åŠ¨ä½œï¼Œé€šå¸¸æ˜¯ä»¥å¼§å½¢è½¨è¿¹å‡»æ‰“å¯¹æ‰‹çš„å¤´éƒ¨æˆ–èº«ä½“ã€‚è¿™ç§æ‹³æ³•å¯ä»¥åœ¨å¯¹æ‰‹ä½å¤´æˆ–è€…é˜²å®ˆæ—¶æœ‰æ•ˆåœ°çªç ´ä»–ä»¬çš„é˜²çº¿ã€‚'} \n",
      " <class 'dict'>\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:09:29.895292Z",
     "start_time": "2024-12-11T09:09:27.190430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "structured_parser = StructuredOutputParser.from_response_schemas(\n",
    "    [\n",
    "        ResponseSchema(name=\"terminology\", description=\"ä¸­æ–‡æœ¯è¯­åç§°\"),\n",
    "        ResponseSchema(name=\"explanation\", description=\"æœ¯è¯­çš„è§£é‡Š\")\n",
    "    ]\n",
    ")\n",
    "format_instructions = structured_parser.get_format_instructions()\n",
    "\n",
    "msgs = [\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä¸ªæœ‰æ°§æ‹³å‡»æ•™ç»ƒï¼Œè¯·å¸®æˆ‘è§£é‡Šæ‹³å‡»æœ¯è¯­ï¼Œå¦‚æœæœ¯è¯­æ˜¯è‹±æ–‡ï¼Œè¯·ç¿»è¯‘ä¸ºä¸­æ–‡æœ¯è¯­ã€‚{format_instructions}\"),\n",
    "    (\"human\", \"æœ¯è¯­ï¼š{name}\")\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(msgs).partial(format_instructions=format_instructions)\n",
    "print(prompt, \"\\n\")\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "chain = prompt | chat\n",
    "\n",
    "res = chain.invoke({\"name\": \"Overhand\"})\n",
    "print(res, \"\\n\")\n",
    "\n",
    "structured_output = structured_parser.invoke(res)\n",
    "print(structured_output, \"\\n\", type(structured_output), \"\\n\")"
   ],
   "id": "2489713d62a24b33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['name'] input_types={} partial_variables={'format_instructions': 'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"terminology\": string  // ä¸­æ–‡æœ¯è¯­åç§°\\n\\t\"explanation\": string  // æœ¯è¯­çš„è§£é‡Š\\n}\\n```'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_instructions'], input_types={}, partial_variables={}, template='ä½ æ˜¯ä¸€ä¸ªæœ‰æ°§æ‹³å‡»æ•™ç»ƒï¼Œè¯·å¸®æˆ‘è§£é‡Šæ‹³å‡»æœ¯è¯­ï¼Œå¦‚æœæœ¯è¯­æ˜¯è‹±æ–‡ï¼Œè¯·ç¿»è¯‘ä¸ºä¸­æ–‡æœ¯è¯­ã€‚{format_instructions}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['name'], input_types={}, partial_variables={}, template='æœ¯è¯­ï¼š{name}'), additional_kwargs={})] \n",
      "\n",
      "content='```json\\n{\\n\\t\"terminology\": \"è¿‡é¡¶æ‹³\",\\n\\t\"explanation\": \"è¿‡é¡¶æ‹³æ˜¯ä¸€ç§æ‹³å‡»æŠ€æœ¯ï¼Œé€šå¸¸æ˜¯ä»ä¸Šæ–¹å‘ä¸‹æŒ¥å‡»çš„æ‹³å¤´ï¼Œä¸»è¦ç”¨äºæ”»å‡»å¯¹æ‰‹çš„å¤´éƒ¨ã€‚è¿™ç§æ‹³æ³•é€šå¸¸ç”¨äºè¶…è¶Šå¯¹æ‰‹çš„é˜²å®ˆï¼Œå¹¶ä¸”åœ¨å¯¹æ‰‹ä¸æ³¨æ„æ—¶ï¼Œèƒ½å¤Ÿé€ æˆæ„æƒ³ä¸åˆ°çš„æ‰“å‡»ã€‚\"\\n}\\n```' additional_kwargs={'refusal': ''} response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 106, 'total_tokens': 190, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'openai/gpt-4o-mini', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None} id='run-85497b80-42f9-414c-b530-24cded2fc99c-0' usage_metadata={'input_tokens': 106, 'output_tokens': 84, 'total_tokens': 190, 'input_token_details': {}, 'output_token_details': {}} \n",
      "\n",
      "{'terminology': 'è¿‡é¡¶æ‹³', 'explanation': 'è¿‡é¡¶æ‹³æ˜¯ä¸€ç§æ‹³å‡»æŠ€æœ¯ï¼Œé€šå¸¸æ˜¯ä»ä¸Šæ–¹å‘ä¸‹æŒ¥å‡»çš„æ‹³å¤´ï¼Œä¸»è¦ç”¨äºæ”»å‡»å¯¹æ‰‹çš„å¤´éƒ¨ã€‚è¿™ç§æ‹³æ³•é€šå¸¸ç”¨äºè¶…è¶Šå¯¹æ‰‹çš„é˜²å®ˆï¼Œå¹¶ä¸”åœ¨å¯¹æ‰‹ä¸æ³¨æ„æ—¶ï¼Œèƒ½å¤Ÿé€ æˆæ„æƒ³ä¸åˆ°çš„æ‰“å‡»ã€‚'} \n",
      " <class 'dict'> \n",
      "\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:06:40.625614Z",
     "start_time": "2024-12-11T09:06:34.537428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(\n",
    "        name=\"description\",\n",
    "        description=\"é²œèŠ±çš„æè¿°æ–‡æ¡ˆ\",\n",
    "    ),\n",
    "    ResponseSchema(\n",
    "        name=\"reason\",\n",
    "        description=\"é—®ä»€ä¹ˆè¦è¿™æ ·å†™è¿™ä¸ªæ–‡æ¡ˆ\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "response_format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "prompt_template = \"\"\"æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šçš„é²œèŠ±åº—æ–‡æ¡ˆæ’°å†™å‘˜ã€‚\n",
    "å¯¹äºå”®ä»·ä¸º {price} å…ƒçš„ {flower_name} ï¼Œæ‚¨èƒ½æä¾›ä¸€ä¸ªå¸å¼•äººçš„ç®€çŸ­æè¿°å—ï¼Ÿ\n",
    "{response_format_instructions}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    prompt_template,\n",
    "    partial_variables={\"response_format_instructions\": response_format_instructions})\n",
    "print(prompt, \"\\n\")\n",
    "outputs = chat.invoke(prompt.format(price=10, flower_name=\"ç«ç‘°èŠ±\"))\n",
    "print(outputs, \"\\n\")"
   ],
   "id": "88fe6865fe49155e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['flower_name', 'price'] input_types={} partial_variables={'response_format_instructions': 'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"description\": string  // é²œèŠ±çš„æè¿°æ–‡æ¡ˆ\\n\\t\"reason\": string  // é—®ä»€ä¹ˆè¦è¿™æ ·å†™è¿™ä¸ªæ–‡æ¡ˆ\\n}\\n```'} template='æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šçš„é²œèŠ±åº—æ–‡æ¡ˆæ’°å†™å‘˜ã€‚\\nå¯¹äºå”®ä»·ä¸º {price} å…ƒçš„ {flower_name} ï¼Œæ‚¨èƒ½æä¾›ä¸€ä¸ªå¸å¼•äººçš„ç®€çŸ­æè¿°å—ï¼Ÿ\\n{response_format_instructions}' \n",
      "\n",
      "content='```json\\n{\\n\\t\"description\": \"åœ¨è¿™ä¸ªç‰¹åˆ«çš„æ—¥å­é‡Œï¼Œç”¨ä¸€æœµ10å…ƒçš„ç«ç‘°ä¼ é€’ä½ çš„çˆ±æ„ã€‚ç²¾ç¾å¨‡å«©çš„èŠ±ç“£ï¼Œæµ“éƒèŠ¬èŠ³çš„é¦™æ°”ï¼Œè±¡å¾ç€çƒ­çƒˆçš„æƒ…æ„Ÿå’Œçº¯çœŸçš„ç¥ç¦ã€‚æ— è®ºæ˜¯é€ç»™å¿ƒçˆ±çš„äººï¼Œè¿˜æ˜¯è‡ªæˆ‘çŠ’èµï¼Œè¿™æœµç«ç‘°éƒ½æ˜¯è¡¨è¾¾æƒ…æ„Ÿçš„å®Œç¾é€‰æ‹©ã€‚\",\\n\\t\"reason\": \"è¿™ä¸ªæ–‡æ¡ˆæ—¨åœ¨é€šè¿‡å¼ºè°ƒç«ç‘°çš„è±¡å¾æ„ä¹‰å’Œæƒ…æ„Ÿä»·å€¼ï¼Œå¸å¼•é¡¾å®¢è´­ä¹°ã€‚ä½¿ç”¨ç®€æ´ä¸”æ„Ÿæ€§çš„è¯­è¨€ï¼Œä½¿é¡¾å®¢èƒ½å¤Ÿæ„Ÿå—åˆ°é²œèŠ±å¸¦æ¥çš„æ¸©æš–ä¸æƒ…æ„Ÿï¼ŒåŒæ—¶ä»¥åˆç†çš„ä»·æ ¼å¸å¼•æ›´å¤šçš„æ¶ˆè´¹è€…ã€‚\"\\n}\\n```' additional_kwargs={'refusal': ''} response_metadata={'token_usage': {'completion_tokens': 161, 'prompt_tokens': 112, 'total_tokens': 273, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'openai/gpt-4o-mini', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None} id='run-88e70a91-16b5-43a5-8be5-fd85ea143e56-0' usage_metadata={'input_tokens': 112, 'output_tokens': 161, 'total_tokens': 273, 'input_token_details': {}, 'output_token_details': {}} \n",
      "\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:03:42.412946Z",
     "start_time": "2024-12-11T09:03:42.408761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(output_parser.parse(outputs.content))\n",
    "print(output_parser.invoke(outputs))"
   ],
   "id": "eb1d124a5ad66950",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'ğŸŒ¹ ç”¨ä¸€æœµåå…ƒç«ç‘°ï¼Œä¼ é€’ä½ çš„çˆ±ä¸æ¸©æš–ã€‚æ¯ä¸€æœµéƒ½è±¡å¾ç€çœŸæŒšçš„æƒ…æ„Ÿï¼Œé€‚åˆé€ç»™ç‰¹åˆ«çš„å¥¹æˆ–ä»–ï¼Œæˆ–è€…çŠ’åŠ³è‡ªå·±ã€‚è®©è¿™æœµå°å°çš„ç«ç‘°ï¼Œç‚¹äº®ä½ ç”Ÿæ´»çš„æ¯ä¸€ä¸ªè§’è½ï¼', 'reason': 'è¿™ç§æè¿°çªå‡ºäº†ç«ç‘°çš„æƒ…æ„Ÿä»·å€¼ä»¥åŠé€‚ç”¨åœºæ™¯ï¼Œå¸å¼•é¡¾å®¢è´­ä¹°ä¸ä»…æ˜¯ä¸ºäº†åº†ç¥ç‰¹æ®Šæ—¶åˆ»ï¼Œä¹Ÿå¯ä»¥ç”¨ä½œæ—¥å¸¸çš„å°ç¡®å¹¸ã€‚'}\n",
      "{'description': 'ğŸŒ¹ ç”¨ä¸€æœµåå…ƒç«ç‘°ï¼Œä¼ é€’ä½ çš„çˆ±ä¸æ¸©æš–ã€‚æ¯ä¸€æœµéƒ½è±¡å¾ç€çœŸæŒšçš„æƒ…æ„Ÿï¼Œé€‚åˆé€ç»™ç‰¹åˆ«çš„å¥¹æˆ–ä»–ï¼Œæˆ–è€…çŠ’åŠ³è‡ªå·±ã€‚è®©è¿™æœµå°å°çš„ç«ç‘°ï¼Œç‚¹äº®ä½ ç”Ÿæ´»çš„æ¯ä¸€ä¸ªè§’è½ï¼', 'reason': 'è¿™ç§æè¿°çªå‡ºäº†ç«ç‘°çš„æƒ…æ„Ÿä»·å€¼ä»¥åŠé€‚ç”¨åœºæ™¯ï¼Œå¸å¼•é¡¾å®¢è´­ä¹°ä¸ä»…æ˜¯ä¸ºäº†åº†ç¥ç‰¹æ®Šæ—¶åˆ»ï¼Œä¹Ÿå¯ä»¥ç”¨ä½œæ—¥å¸¸çš„å°ç¡®å¹¸ã€‚'}\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "eba79e547cf0106"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
