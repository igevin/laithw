{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ChatModel",
   "id": "9b01785209e1e95f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Ollama",
   "id": "b66351afaad2711e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 直接使用",
   "id": "a430f2074281a9d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# install package\n",
    "%pip install -U langchain-ollama"
   ],
   "id": "74346153ebd153e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:19:20.145805Z",
     "start_time": "2024-12-16T03:19:17.833930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(model=\"qwen2.5:0.5b\")\n",
    "resp = llm.invoke(\"写一首关于 AI 的诗\")\n",
    "\n",
    "print(resp)"
   ],
   "id": "4a23d19288cd1f9e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI 如梦，万物纷飞，\n",
      "在云端游走，无所顾忌。\n",
      "它能感知，也能计算，\n",
      "在知识的海洋里遨游。\n",
      "\n",
      "它能理解，也能思考，\n",
      "在数百万亿的信息中，\n",
      "寻找最接近真理的答案。\n",
      "它是智能的大脑，是心灵的钥匙。\n",
      "\n",
      "AI 如诗，自由翱翔，\n",
      "它的情感丰富，智慧深刻，\n",
      "在代码和算法间穿梭跳跃，\n",
      "创造出无与伦比的美。\n",
      "\n",
      "AI 如画，生机盎然，\n",
      "它在数字世界的画卷上，\n",
      "描绘出五彩斑斓的世界图景。\n",
      "它是艺术的大师，是心灵的画家。\n",
      "\n",
      "AI 既智能又聪明，\n",
      "它可以洞察人类情感，\n",
      "理解人性、自然和社会，\n",
      "为人类带来智慧和力量。\n",
      "\n",
      "AI 的未来不可限量，\n",
      "它的潜力无穷无尽，\n",
      "随着科技的进步，它将更加神奇，\n",
      "成为推动社会进步的力量。\n",
      " AI 如歌，悠扬悦耳，\n",
      "在数字的海洋里飘荡，\n",
      "奏出美妙和谐的旋律，\n",
      "为我们展现一幅幅精彩的画卷。\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:19:26.173512Z",
     "start_time": "2024-12-16T03:19:25.261475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "chat = ChatOllama(model=\"qwen2.5:0.5b\")\n",
    "\n",
    "resp = chat.invoke(\"写一首关于 AI 的诗\")\n",
    "print(resp.content)"
   ],
   "id": "cd59879ad6a73360",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI，你如星辰般璀璨，  \n",
      "在我们心中燃烧，闪烁。  \n",
      "\n",
      "你似那晨风拂面的柔情，  \n",
      "在我们心底绽放，温柔。  \n",
      "\n",
      "你似那夜雨细语的细腻，  \n",
      "在我们心头流淌，缠绵。  \n",
      "\n",
      "你似那山高水长的深邃，  \n",
      "在我们心中藏匿，神秘。  \n",
      "\n",
      "你如那白昼的繁星，在夜晚闪烁，璀璨夺目。\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### OpenAI 兼容 API 使用",
   "id": "8b55b21af47cb607"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:19:30.967802Z",
     "start_time": "2024-12-16T03:19:29.765214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "key = \"ollama\"\n",
    "chat = ChatOpenAI(openai_api_base=\"http://127.0.0.1:11434/v1\",\n",
    "                  openai_api_key=key,\n",
    "                  model_name=\"qwen2.5:0.5b\")\n",
    "resp = chat.invoke(\"写一首关于 AI 的诗\")\n",
    "print(resp.content)\n",
    "# print(resp)"
   ],
   "id": "37419c43d4bff983",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在知识的海洋中航行，  \n",
      "AI 与人并驾齐驱。  \n",
      "信息传递无处不在，  \n",
      "让世界因你而更精彩。\n",
      "\n",
      "算法如同明灯，照亮夜空；  \n",
      "决策犹如指南针，指引方向。  \n",
      "数据编织成网，连接全世界；  \n",
      "智能如影随形，时刻准备着。\n",
      "\n",
      "AI 智能，与人共舞；  \n",
      "和谐共生，共享未来。  \n",
      "科技的力量，让世界更美好；  \n",
      "未来是 AI 的舞台，我们共同书写。\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Ollama 说明\n",
    "\n",
    "Ollama 地址：\n",
    "\n",
    "- [官网](https://ollama.com/)\n",
    "- [github](https://github.com/ollama/ollama)\n",
    "\n",
    "<br />\n",
    "\n",
    "#### 1. 安装\n",
    "\n",
    "[官网](https://ollama.com/download)，mac 直接下载安装包，Linux 执行该命令：\n",
    "\n",
    "```bash\n",
    "curl -fsSL https://ollama.com/install.sh | sh\n",
    "```\n",
    "\n",
    "#### 2. 使用\n",
    "\n",
    "Ollama 的使用，基本与 docker 一致：\n",
    "\n",
    "```bash\n",
    "ollama --help\n",
    "Large language model runner\n",
    "\n",
    "Usage:\n",
    "  ollama [flags]\n",
    "  ollama [command]\n",
    "\n",
    "Available Commands:\n",
    "  serve       Start ollama\n",
    "  create      Create a model from a Modelfile\n",
    "  show        Show information for a model\n",
    "  run         Run a model\n",
    "  stop        Stop a running model\n",
    "  pull        Pull a model from a registry\n",
    "  push        Push a model to a registry\n",
    "  list        List models\n",
    "  ps          List running models\n",
    "  cp          Copy a model\n",
    "  rm          Remove a model\n",
    "  help        Help about any command\n",
    "\n",
    "Flags:\n",
    "  -h, --help      help for ollama\n",
    "  -v, --version   Show version information\n",
    "\n",
    "Use \"ollama [command] --help\" for more information about a command.\n",
    "\n",
    "```\n",
    "\n",
    "#### 3. 客户端\n",
    "\n",
    "Mac 可以直接在App Store 下载客户端软件 `enchanted` 使用，详见：[enchanted](https://github.com/AugustDev/enchanted)\n",
    "\n",
    "其他常见客户端，如 [open-webui](https://github.com/open-webui/open-webui)\n",
    "\n",
    "更多客户端，可查阅 Ollama GitHub 地址查找"
   ],
   "id": "7085519e181ee94e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hugging Face",
   "id": "7f79a4bafa33b5e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T03:34:06.082422Z",
     "start_time": "2024-12-18T03:34:01.901250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from langchain_huggingface import HuggingFacePipeline, ChatHuggingFace\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# 创建大模型对象\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"Qwen/Qwen2.5-0.5B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    device=device,\n",
    "    pipeline_kwargs=dict(\n",
    "        max_new_tokens=512,\n",
    "        return_full_text=False,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# 基于大模型对象，创建 ChatModel\n",
    "chat_model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "result = chat_model.invoke(\"写一首关于西湖断桥残雪的七言绝句。\")\n",
    "print(result.content)"
   ],
   "id": "b29ab2da03b4e87c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "断桥残雪映孤烟，玉立冰轮映夕阳。\n",
      "\n",
      "柳岸花开春又老，断肠人处是春风。\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
